{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad4d51-42bb-4101-b2f6-a24c6f88621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "JOB_QUEUE_ARN = 'arn:aws:batch:us-west-2:176245438256:job-queue/BatchJobQueue-fzRFEEEvL4l1jLRp'\n",
    "\n",
    "os.environ['AWS_PROFILE'] = 'saml-pub'\n",
    "batch = boto3.client('batch')\n",
    "log_client = boto3.client('logs')\n",
    "\n",
    "\n",
    "def chunk(itr, n: int = 100):\n",
    "    for i in range(0, len(itr), n):\n",
    "        yield itr[i:i + n]\n",
    "\n",
    "def get_all_batch_jobs():\n",
    "    response = batch.list_jobs(jobQueue=JOB_QUEUE_ARN, jobStatus='FAILED')\n",
    "    jobs = response['jobSummaryList']\n",
    "\n",
    "    while 'nextToken' in response:\n",
    "        response = batch.list_jobs(jobQueue=JOB_QUEUE_ARN, jobStatus='FAILED', nextToken=response['nextToken'])\n",
    "        jobs.extend(response['jobSummaryList'])\n",
    "\n",
    "    return jobs\n",
    "\n",
    "def get_last_log_event(log_stream):\n",
    "    try:\n",
    "        next_token = None\n",
    "        n_events_requested = 1\n",
    "        events = []\n",
    "\n",
    "        # FFS: https://github.com/boto/boto3/issues/3718\n",
    "        # This implementation is what was recommended in the boto3 issue above but is HTTP request intensive as you're\n",
    "        # paging through a pile of empty pages of events.\n",
    "        # it should be possible to refactor it such that you:\n",
    "        #    - describe the log stream: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/logs/client/describe_log_streams.html\n",
    "        #    - use the lastEventTimestamp in the response above to set a startTime and endTime in the get_log_events call: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/logs/client/get_log_events.html\n",
    "        # which would make it only 2 HTTP calls ever.\n",
    "        while len(events) < n_events_requested:\n",
    "            log_query = {\n",
    "                'logGroupName': '/aws/batch/job',\n",
    "                'logStreamName': log_stream,\n",
    "            }\n",
    "            if next_token:\n",
    "                log_query['nextToken'] = next_token\n",
    "\n",
    "            response = log_client.get_log_events(**log_query)\n",
    "            events.extend(response['events'])\n",
    "\n",
    "            if 'nextBackwardToken' in response:\n",
    "                if response['nextBackwardToken'] == next_token:\n",
    "                    break # no new token, so at the start\n",
    "                next_token = response['nextBackwardToken']\n",
    "\n",
    "\n",
    "        return events[-1]['message']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_attempts(batch_jobs):\n",
    "    batch_attempts = []\n",
    "    for jobs in tqdm(chunk(batch_jobs, 100), total=np.ceil(len(batch_jobs) / 100)):\n",
    "        response = batch.describe_jobs(jobs=[job['jobId'] for job in jobs])\n",
    "        for job in response['jobs']:\n",
    "            for attempt in job['attempts']:\n",
    "                container = attempt['container']\n",
    "\n",
    "                log_line = None\n",
    "                log_stream = container.get('logStreamName')\n",
    "                if log_stream:\n",
    "                    log_line = get_last_log_event(log_stream)\n",
    "\n",
    "                batch_attempts.append(\n",
    "                    (job['jobName'], job['jobId'] ,attempt['statusReason'] ,container.get('reason'), log_line)\n",
    "                )\n",
    "    return batch_attempts\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_jobs = get_all_batch_jobs()\n",
    "    batch_attempts = get_attempts(batch_jobs)\n",
    "\n",
    "    # NOTE: We *name* batch jobs using their associated HyP3 job_id; this job_id is the batch job_id\n",
    "    df = pd.DataFrame(batch_attempts, columns=['job_name', 'job_id', 'status', 'reason', 'last_log_line'])\n",
    "    df.to_csv('scripts/2024-08-28-ARIA-failures.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aria_hyp3_env",
   "language": "python",
   "name": "aria_hyp3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
