{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f31db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import hyp3_sdk\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb356a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "77889399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isce_jobs4resubmit(jobs_dicts:list):\n",
    "    job_definition = {'name': None,\n",
    "                      'job_parameters': None,\n",
    "                      'job_type': 'INSAR_ISCE'\n",
    "                     }\n",
    "\n",
    "    prepared_jobs = []\n",
    "    for job in jobs_dicts:\n",
    "        prepared_job = deepcopy(job_definition)\n",
    "        prepared_job['name'] = job['name']\n",
    "        prepared_job['job_parameters'] = job['job_parameters']\n",
    "        prepared_job['job_type'] = job['job_type']\n",
    "        prepared_jobs.append(prepared_job)\n",
    "    return prepared_jobs\n",
    "\n",
    "def raider_jobs4resubmit(jobs_dicts:list):\n",
    "    job_definition = {\n",
    "        'name': 're-run RAiDER step',  # optional: provide a name\n",
    "        \"job_type\": \"ARIA_RAIDER\",\n",
    "        \"job_parameters\": {\n",
    "            # \"job_id\": \"27836b79-e5b2-4d8f-932f-659724ea02c3\",\n",
    "            # \"weather_model\": \"ERA5\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    prepared_jobs = []\n",
    "    for job in jobs_dicts:\n",
    "        prepared_job = deepcopy(job_definition)\n",
    "        prepared_job['name'] = job['name'] + '_rerun_raider'\n",
    "        prepared_job['job_parameters']['job_id'] = job['job_id']\n",
    "        prepared_job['job_parameters']['weather_model'] = job['job_parameters']['weather_model'] \n",
    "        prepared_jobs.append(prepared_job)\n",
    "    return prepared_jobs\n",
    "\n",
    "def split_failed_jobs(failed_jobs):\n",
    "    flag_insar_job = lambda x, y: (x.job_type == 'INSAR_ISCE') & (len(x.processing_times)==y)\n",
    "    # isce\n",
    "    isce_jobs = [j.to_dict() for j in failed_jobs if flag_insar_job(j, 1)]\n",
    "    # raider\n",
    "    raider_jobs_new = [j.to_dict() for j in failed_jobs if flag_insar_job(j, 2)] \n",
    "    raider_jobs = [j.to_dict() for j in failed_jobs if j.job_type == 'ARIA_RAIDER']\n",
    "    raider_jobs = raider_jobs_new + raider_jobs\n",
    "    return isce_jobs, raider_jobs\n",
    "\n",
    "def get_request_date(job_dict):\n",
    "    job_date = datetime.datetime.strptime(job_dict['request_time'], '%Y-%m-%dT%H:%M:%S%z')\n",
    "    return datetime.datetime.strftime(job_date,'%Y-%d-%m')  \n",
    "\n",
    "# TODO: add function to find duplicate jobs to filter out same jobs\n",
    "# for now track it by date\n",
    "class access_hyp3_resubmit():\n",
    "    def __init__(self, hyp3_jobs):\n",
    "        # Filter to failed jobs\n",
    "        failed_jobs = hyp3_jobs.filter_jobs(succeeded=False, pending=False,\n",
    "                                            running=False, failed=True)\n",
    "        print(f'All jobs:\\n {failed_jobs}')\n",
    "\n",
    "        # Failed at topssApp step\n",
    "        self.isce_jobs, self.raider_jobs = split_failed_jobs(failed_jobs)\n",
    "        print(f'Topsapp jobs: {len(self.isce_jobs)}')\n",
    "        print(f' Sumbission dates: {np.unique(list(map(get_request_date, self.isce_jobs)))}')\n",
    "\n",
    "        # Failed at raider step\n",
    "        print(f'Raider jobs: {len(self.raider_jobs)}')\n",
    "        print(f' Sumbission dates: {np.unique(list(map(get_request_date, self.raider_jobs)))}')\n",
    "\n",
    "    def prepare_jobs(self, batch_size=200):\n",
    "        self.prepared_isce = isce_jobs4resubmit(self.isce_jobs)\n",
    "        self.prepared_raider = raider_jobs4resubmit(self.raider_jobs)\n",
    "        # isce\n",
    "        self.isce_resubmit = [batch for batch in hyp3_sdk.util.chunk(self.prepared_isce, batch_size)]\n",
    "        msg = f'Prepared isce jobs: {len(self.prepared_isce)} in {len(self.isce_resubmit[0])}'\n",
    "        msg += f'x {len(self.isce_resubmit)} batches'\n",
    "        print(msg) \n",
    "        # raider\n",
    "        self.raider_resubmit = [batch for batch in hyp3_sdk.util.chunk(self.prepared_raider, batch_size)]\n",
    "        msg = f'Prepared raider jobs: {len(self.prepared_raider)} in {len(self.raider_resubmit[0])}'\n",
    "        msg += f'x {len(self.raider_resubmit)} batches'\n",
    "        print(msg)\n",
    "        \n",
    "    def submit_isce(self):\n",
    "        print(f'Submitting: {len(self.prepared_isce)} jobs')\n",
    "        for batch in tqdm(self.isce_resubmit):\n",
    "            hyp3_isce.submit_prepared_jobs(batch)\n",
    "\n",
    "    def submit_raider(self):\n",
    "        print(f'Submitting: {len(self.prepared_raider)} jobs')\n",
    "        for batch in tqdm(self.raider_resubmit):\n",
    "            hyp3_isce.submit_prepared_jobs(batch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f45fd",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e61723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses .netrc; add `prompt=True` to prompt for credentials;\n",
    "hyp3_isce = hyp3_sdk.HyP3('https://hyp3-a19-jpl.asf.alaska.edu', prompt=True)\n",
    "# hyp3_isce = hyp3_sdk.HyP3('https://hyp3-tibet-jpl.asf.alaska.edu', prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1831ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219029 HyP3 Jobs: 92785 succeeded, 124106 failed, 1001 running, 1137 pending.\n"
     ]
    }
   ],
   "source": [
    "# Since the campaign first date\n",
    "jobs = hyp3_isce.find_jobs(user_id='access_cloud_based_insar',\n",
    "                           start=datetime.datetime(2024, 2, 6), \n",
    "                           end=datetime.datetime(2024, 5, 21))\n",
    "print(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c461d971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98418 HyP3 Jobs: 38804 succeeded, 57476 failed, 1003 running, 1135 pending.\n"
     ]
    }
   ],
   "source": [
    "# Since I started\n",
    "jobs = hyp3_isce.find_jobs(start=datetime.datetime(2024, 4, 25), \n",
    "                           end=datetime.datetime(2024, 5, 21),\n",
    "                           user_id='access_cloud_based_insar')\n",
    "print(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8c080",
   "metadata": {},
   "source": [
    "Track jobs by the submission dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "eafb8dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79343 HyP3 Jobs: 26274 succeeded, 50931 failed, 1003 running, 1135 pending.\n"
     ]
    }
   ],
   "source": [
    "jobs = hyp3_isce.find_jobs(start=datetime.datetime(2024, 5, 5), \n",
    "                           end=datetime.datetime(2024, 5, 21),\n",
    "                           user_id='access_cloud_based_insar')\n",
    "print(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "108fbee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_jobs_flag = dict(succeeded=False, pending=False,\n",
    "                        running=False, failed=True)\n",
    "failed_jobs = jobs.filter_jobs(**failed_jobs_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b0477838",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, r = split_failed_jobs(failed_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9cd8d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_id = [x['job_id'] for x in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b02cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "619c57c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4815360217136865304"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(tuple(failed_jobs[2].job_parameters.get('granules')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aca6b567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jobs:\n",
      " 50868 HyP3 Jobs: 0 succeeded, 50868 failed, 0 running, 0 pending.\n",
      "Topsapp jobs: 2201\n",
      " Sumbission dates: ['2024-05-05']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raider jobs: 48667\n",
      " Sumbission dates: ['2024-05-05' '2024-07-05']\n",
      "Prepared isce jobs: 2201 in 200x 12 batches\n",
      "Prepared raider jobs: 48667 in 200x 244 batches\n"
     ]
    }
   ],
   "source": [
    "resumbission_jobs = access_hyp3_resubmit(failed_jobs)\n",
    "resumbission_jobs.prepare_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "233bd969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting: 2201 jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:23<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "resumbission_jobs.submit_isce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3edba570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "26532 HyP3 Jobs: 3 succeeded, 24330 failed, 234 running, 1965 pending.\n",
      "##########\n",
      "All jobs:\n",
      " 24330 HyP3 Jobs: 0 succeeded, 24330 failed, 0 running, 0 pending.\n",
      "Topsapp jobs: 2\n",
      " Sumbission dates: ['2024-07-05']\n",
      "Raider jobs: 24328\n",
      " Sumbission dates: ['2024-07-05']\n"
     ]
    }
   ],
   "source": [
    "jobs = hyp3_isce.find_jobs(user_id='access_cloud_based_insar',\n",
    "                           start=datetime.datetime(2024, 5, 6), \n",
    "                           end=datetime.datetime(2024, 5, 21))\n",
    "failed_jobs_flag = dict(succeeded=False, pending=False,\n",
    "                        running=False, failed=True)\n",
    "\n",
    "print('#' * 10)\n",
    "print(jobs)\n",
    "print('#' * 10)\n",
    "rjobs = access_hyp3_resubmit(jobs.filter_jobs(**failed_jobs_flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bea33673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['https://hyp3-a19-jpl-contentbucket-1wfnatpznlg8b.s3.us-west-2.amazonaws.com/6716cbda-0088-4262-920a-5f5287a4dbc7/6716cbda-0088-4262-920a-5f5287a4dbc7.log'],\n",
       " ['https://hyp3-a19-jpl-contentbucket-1wfnatpznlg8b.s3.us-west-2.amazonaws.com/9d27256a-acf3-4ed9-92b0-c0d04374a6c8/9d27256a-acf3-4ed9-92b0-c0d04374a6c8.log'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check failed jobs\n",
    "all_logs = [j['logs'] for j in rjobs.raider_jobs]\n",
    "all_logs[0], all_logs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2563cf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfailed_logs = []\\nfor ix, log in enumerate(all_logs):\\n    r = requests.get(log)\\n    failed_logs.append({ix: r.text.splitlines()[-3:]})'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get log last 3 lines\n",
    "'''\n",
    "failed_logs = []\n",
    "for ix, log in enumerate(all_logs):\n",
    "    r = requests.get(log)\n",
    "    failed_logs.append({ix: r.text.splitlines()[-3:]})'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4f81c",
   "metadata": {},
   "source": [
    "## asf search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "01dc2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asf_search as asf\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dc26e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires asf_search > 7.0.8\n",
    "opts = asf.ASFSearchOptions(\n",
    "    shortName='ARIA_S1_GUNW',\n",
    "    #relativeOrbit=[13],\n",
    "    #flightDirection='DESCENDING',\n",
    "    #processingLevel='GUNW_STD',\n",
    "    intersectsWith='POLYGON((-127.992 32.2865,-115.5115 32.2865,-115.5115 49.1812,-127.992 49.1812,-127.992 32.2865))',\n",
    "    collectionAlias=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5510d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = asf.search(opts=opts)\n",
    "gdf = gpd.GeoDataFrame.from_features(scenes.geojson(), crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "21e3e156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44594, 30)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28594d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = gdf.fileID.apply(lambda x: int(x.split('-')[-1].split('_')[0].split('v')[-1]))\n",
    "version.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aria_hyp3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
